{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mlt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from string import ascii_letters\n",
    "from pylab import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "from fancyimpute import KNN\n",
    "from scipy.stats import chi2_contingency\n",
    "from random import randrange, uniform\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory\n",
    "os.chdir(\"/Users/ad/Desktop/Project 1\")\n",
    "\n",
    "# Check working directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data to python\n",
    "train = pd.read_csv(\"Train_data.csv\")\n",
    "test = pd.read_csv(\"Test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train.append(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning codes to each state\n",
    "\n",
    "keys = data['state'].unique().tolist()\n",
    "values = list(range(len(keys)))\n",
    "state_codes = dict(zip(keys,values))\n",
    "data['state'] = data['state'].map(state_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Continuous and Categorical Variables\n",
    "# Excluding phone.number variable and dependent variable\n",
    "\n",
    "cnames= [\"account.length\",\"number.vmail.messages\", \"total.day.minutes\",\"total.day.calls\", \"total.day.charge\",\n",
    "         \"total.eve.minutes\",\"total.eve.calls\",\"total.eve.charge\",\"total.night.minutes\", \n",
    "         \"total.night.calls\",\"total.night.charge\",\"total.intl.minutes\",\"total.intl.calls\", \"total.intl.charge\", \n",
    "         \"number.customer.service.calls\"]\n",
    "\n",
    "cat_names= [\"state\", \"area.code\", \"international.plan\",\"voice.mail.plan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning levels to the categories\n",
    "lis = []\n",
    "for i in range(0, data.shape[1]):\n",
    "    #print(i)\n",
    "    if(data.iloc[:,i].dtypes == 'object'):\n",
    "        data.iloc[:,i] = pd.Categorical(data.iloc[:,i])\n",
    "        #print(data.iloc[i])\n",
    "        data.iloc[:,i] = data.iloc[:,i].cat.codes \n",
    "        data.iloc[:,i] = data.iloc[:,i].astype('object')\n",
    "        \n",
    "        lis.append(data.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking correlations values of continous variables\n",
    "corr = data.corr()\n",
    "corr.style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking correlations of continous variables\n",
    "# Correlation Plot\n",
    "df_corr = data.loc[:,cnames]\n",
    "\n",
    "corr = df_corr.corr()\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking dependency of dependent variable on categorical variables\n",
    "# Loop for chi square values\n",
    "# Variable area.code not significant\n",
    "\n",
    "for i in cat_names:\n",
    "    print(i)\n",
    "    chi2, p, dof, ex = chi2_contingency(pd.crosstab(data['Churn'], data[i]))\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking counts of Target variable\n",
    "plt.figure(figsize = (9,6)),\n",
    "sns.set(font_scale = 1),\n",
    "sns.countplot(x = 'Churn', data = data)\n",
    "plt.xlabel ( 'Churn' , fontsize = 20)\n",
    "plt.ylabel ( 'Counts' , fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Number of Voicemail Messages by Class\n",
    "\n",
    "plt.figure(figsize = (10,15))\n",
    "data.hist('number.vmail.messages', by = 'Churn') \n",
    "plt.ylabel('Count' , fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot total.intl.calls by class\n",
    "\n",
    "plt.figure(figsize = (10,15))\n",
    "data.hist('total.intl.calls', by = 'Churn') \n",
    "plt.ylabel('Count' , fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number.customer.service.calls by class\n",
    "\n",
    "plt.figure(figsize = (10,15))\n",
    "data.hist('number.customer.service.calls', by = 'Churn') \n",
    "plt.ylabel('Count' , fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot of States\n",
    "plt.figure(figsize = (15,10))\n",
    "sns.countplot('state', data= data) \n",
    "plt.xlabel('State',fontsize = 20)\n",
    "plt.ylabel('Count',fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MISSING VALUE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Missing Values\n",
    "\n",
    "missing_val= pd.DataFrame(data.isnull().sum())\n",
    "missing_val \n",
    "#No missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot to visualize outliers\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.boxplot(data['total.intl.minutes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect and delete outliers from data\n",
    "for i in cnames:\n",
    "    print(i)\n",
    "    q75, q25 = np.percentile(data.loc[:,i], [75, 25])\n",
    "    iqr = q75 - q25\n",
    "    \n",
    "    min = q25 - (iqr * 1.5)\n",
    "    max = q75 + (iqr * 1.5)\n",
    "    \n",
    "    print(min)\n",
    "    print(max)\n",
    "    data.loc[data.loc[:,i] < min,i]= np.nan\n",
    "    data.loc[data.loc[:,i] > max,i]= np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the missing values\n",
    "missing_val= pd.DataFrame(data.isnull().sum())\n",
    "print(data.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values with KNN\n",
    "data = pd.DataFrame(KNN(k = 3).fit_transform(data), columns = data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = data.copy()\n",
    "#data = data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Variables\n",
    "\n",
    "data = data.drop([\"phone.number\",\"area.code\",\"total.day.charge\",\"total.eve.charge\",\"total.night.charge\",\"total.intl.charge\"], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normality Check\n",
    "%matplotlib inline\n",
    "plt.hist(data['number.customer.service.calls'], bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_norm = [\"number.vmail.messages\",\"number.customer.service.calls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation\n",
    "for i in not_norm:\n",
    "    print(i)\n",
    "    data[i] = (data[i] - data[i].min())/ (data[i].max()- data[i].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_norm = [\"account.length\",\"total.day.minutes\", \"total.day.calls\", \"total.eve.minutes\", \"total.eve.calls\",\"total.night.minutes\",\"total.night.calls\",\"total.intl.minutes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "for i in var_norm:\n",
    "    print(i)\n",
    "    data[i]= (data[i]- data[i].mean())/data[i].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.values[:, 0:14] # Independent Variable\n",
    "Y = data.values[:,14] # Dependent Variable\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling of minor class target variable\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "print(\"Before oversampling, count of class '1': {}\".format(sum(Y_train == 1)))\n",
    "print(\"Before oversampling, count of class '0': {}\".format(sum(Y_train == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over, Y_train_over = smote.fit_sample(X_train, Y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"After oversampling, count of class '1': {}\".format(sum(Y_train_over == 1)))\n",
    "print(\"After oversampling, count of class '0': {}\".format(sum(Y_train_over == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before oversampling, count of class '1': {}\".format(sum(Y_test == 1)))\n",
    "print(\"Before oversampling, count of class '0': {}\".format(sum(Y_test == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_over, Y_test_over = smote.fit_sample(X_test, Y_test.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"After oversampling, count of class '1': {}\".format(sum(Y_test_over == 1)))\n",
    "print(\"After oversampling, count of class '0': {}\".format(sum(Y_test_over == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion= 'entropy').fit(X_train_over, Y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict new test cases\n",
    "y_pred = clf.predict(X_test_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dot file to visualize tree ( http://webgraphviz.com/)\n",
    "#dotfile= open(\"pt.dot\", 'w')\n",
    "#df = tree.export_graphviz(clf, out_file= dotfile, feature_names= data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the accuracy\n",
    "accuracy_score(Y_test_over, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "CM = confusion_matrix(Y_test_over, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Confusion Matrix\n",
    "CM = pd.crosstab(Y_test_over, y_pred)\n",
    "\n",
    "# Store TP,TN,FP,FN values\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "# Accuracy\n",
    "#(TN+TP)/(TN+TP+FN+FP)\n",
    "\n",
    "# FNR\n",
    "(FN*100)/(FN+TP)\n",
    "\n",
    "# Recall\n",
    "(TP*100)/(TP+FN)\n",
    "\n",
    "# Specificity\n",
    "(TN*100)/(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF_model= RandomForestClassifier(n_estimators = 500).fit(X_train_over, Y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_predictions = RF_model.predict(X_test_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Confusion Matrix\n",
    "\n",
    "CM = pd.crosstab(Y_test_over, RF_predictions)\n",
    "\n",
    "# Store TP,TN,FP,FN values\n",
    "\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "# Check Accuracy of the model\n",
    "#((TN+TP)*100)/(TN+FN+TP+FP)\n",
    "\n",
    "# Check FNR\n",
    "#(FN*100)/(FN+TP)\n",
    "\n",
    "# Recall\n",
    "#(TP*100)/(TP+FN)\n",
    "\n",
    "# Specificity\n",
    "#(TN*100)/(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Target Variable with 0 and 1\n",
    "data['Churn']= data['Churn'].replace('No', 0)\n",
    "data['Churn']= data['Churn'].replace('Yes', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_logit= pd.DataFrame(data['Churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_logit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnames= [\"account.length\", \"number.vmail.messages\", \"total.day.minutes\",\"total.day.calls\",\n",
    "         \"total.eve.minutes\",\"total.eve.calls\",\"total.night.minutes\", \n",
    "         \"total.night.calls\",\"total.intl.minutes\",\"total.intl.calls\", \n",
    "         \"number.customer.service.calls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add continuous variable\n",
    "data_logit = data_logit.join(data[cnames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummies for categorical variables\n",
    "cat_names= [\"international.plan\",\"voice.mail.plan\"]\n",
    "\n",
    "for i in cat_names:\n",
    "    temp = pd.get_dummies(data[i], prefix = i)\n",
    "    data_logit = data_logit.join(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_logit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = np.random.rand(len(data_logit)) < 0.8\n",
    "\n",
    "train = data_logit[sample_index]\n",
    "test = data_logit[~sample_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns indexes for independent variables\n",
    "train_cols = train.columns[1:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build logistic regression model\n",
    "import statsmodels.api as sm\n",
    "\n",
    "logit = sm.Logit(train['Churn'], train[train_cols]).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Test Data\n",
    "test['Actual_prob'] = logit.predict(test[train_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Actualval'] = 1\n",
    "test.loc[test.Actual_prob < 0.5, 'Actualval'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Confusion Matrix\n",
    "\n",
    "CM = pd.crosstab(test['Churn'], test['Actualval'])\n",
    "\n",
    "# Store TP,TN,FP,FN values\n",
    "\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "# Check Accuracy of the model\n",
    "#((TN+TP)*100)/(TN+FN+TP+FP)\n",
    "\n",
    "# Check FNR\n",
    "#(FN*100)/(FN+TP)\n",
    "\n",
    "# Recall\n",
    "#(TP*100)/(TP+FN)\n",
    "\n",
    "# Specificity\n",
    "#(TN*100)/(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KNN_model = KNeighborsClassifier(n_neighbors = 11).fit(X_train_over, Y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the test cases\n",
    "KNN_pred = KNN_model.predict(X_test_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Confusion Matrix\n",
    "\n",
    "CM = pd.crosstab(Y_test_over, KNN_pred)\n",
    "\n",
    "# Store TP,TN,FP,FN values\n",
    "\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "# Check Accuracy of the model\n",
    "((TN+TP)*100)/(TN+FN+TP+FP)\n",
    "\n",
    "\n",
    "# Check FNR\n",
    "#(FN*100)/(FN+TP)\n",
    "\n",
    "# Recall\n",
    "#(TP*100)/(TP+FN)\n",
    "\n",
    "# Specificity\n",
    "#(TN*100)/(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Build Naive Bayes model\n",
    "NB_model = GaussianNB().fit(X_train_over, Y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the test cases\n",
    "NB_pred = NB_model.predict(X_test_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Confusion Matrix\n",
    "\n",
    "CM = pd.crosstab(Y_test_over, NB_pred)\n",
    "\n",
    "# Store TP,TN,FP,FN values\n",
    "\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "# Check Accuracy of the model\n",
    "#((TN+TP)*100)/(TN+FN+TP+FP)\n",
    "\n",
    "\n",
    "# Check FNR\n",
    "#(FN*100)/(FN+TP)\n",
    "\n",
    "# Recall\n",
    "#(TP*100)/(TP+FN)\n",
    "\n",
    "# Specificity\n",
    "#(TN*100)/(TN+FP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
